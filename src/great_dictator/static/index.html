<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Great Dictator</title>
    <style>
        body {
            font-family: system-ui, sans-serif;
            max-width: 600px;
            margin: 50px auto;
            padding: 20px;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            font-size: 16px;
            cursor: pointer;
        }
        #record { background: #4CAF50; color: white; border: none; }
        #stop { background: #f44336; color: white; border: none; }
        #stop:disabled { background: #ccc; }
        textarea {
            width: 100%;
            height: 200px;
            margin-top: 20px;
            padding: 10px;
            font-size: 16px;
        }
        #status { margin-top: 10px; color: #666; }
    </style>
</head>
<body>
    <h1>Great Dictator</h1>
    <div>
        <button id="record">Record</button>
        <button id="stop" disabled>Stop</button>
    </div>
    <div id="status"></div>
    <textarea id="transcription" placeholder="Transcription will appear here..."></textarea>

    <script>
        let mediaRecorder;
        let audioChunks = [];

        const recordBtn = document.getElementById('record');
        const stopBtn = document.getElementById('stop');
        const statusEl = document.getElementById('status');
        const transcriptionEl = document.getElementById('transcription');

        recordBtn.addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');

                    statusEl.textContent = 'Transcribing...';
                    try {
                        const response = await fetch('/transcribe', {
                            method: 'POST',
                            body: formData
                        });
                        const html = await response.text();
                        transcriptionEl.value += html + '\n';
                        statusEl.textContent = 'Done';
                    } catch (error) {
                        statusEl.textContent = 'Error: ' + error.message;
                    }

                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                recordBtn.disabled = true;
                stopBtn.disabled = false;
                statusEl.textContent = 'Recording...';
            } catch (error) {
                statusEl.textContent = 'Error: ' + error.message;
            }
        });

        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                recordBtn.disabled = false;
                stopBtn.disabled = true;
            }
        });
    </script>
</body>
</html>
